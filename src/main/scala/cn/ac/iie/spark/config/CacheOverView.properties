user.name=hadoop-user
es.nodes=10.0.30.101,10.0.30.102,10.0.30.105,10.0.30.107
#es.nodes=10.0.10.4,10.0.10.5
es.port=9200
kafka.brokers=10.0.30.103:9092,10.0.30.104:9092
kafka.topics=cachetest
kafka.consumer=null
auto.offset.reset=smallest
zookeeper.nodes=null
day.executor.memory=5g
hour.executor.memory=5g
day.cores.max=5
hour.cores.max=3
mysqlConn=jdbc:mysql://10.0.30.14:3306/rmp?useUnicode=true&characterEncoding=utf-8
#mysqlConn=jdbc:mysql://10.0.10.3:3306/rmp?useUnicode=true&characterEncoding=utf-8
mysql.user=root
#开发环境
mysql.pwd=qwertyu
#北京局点
#mysql.pwd=yyb123
flume.test.big.node=10.0.30.106
flume.test.small.node=10.0.30.107
flume.local.big.source=10.0.10.11
flume.local.small.source=10.0.10.12
flume.local.big.port=20000
flume.local.small.port=19999
#spark.master=spark://10.0.10.8:7077
spark.master=yarn
#spark.master=spark://10.0.30.101:7077
#spark.master=local[2]
runtime.cores.max=5
hdfs.smallfile.path=hdfs://10.0.10.2:8020/user/hadoop-user/coll_data/cache_log/jiangxi/791/small/
hdfs.bigfile.path=hdfs://10.0.10.2:8020/user/hadoop-user/coll_data/cache_log/jiangxi/791/small/
queue=scheduler