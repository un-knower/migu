#spark.master = spark://10.0.30.101:7077
spark.master = local[*]
#spark.master = yarn
spark.app.name = app
#spark.submit.deployMode = client
spark.serializer = org.apache.spark.serializer.KryoSerializer
es.index.auto.create = true
es.nodes = 58.244.48.32:9200
es.port = 9200
#spark.cores.max = 12
#spark.executor.cores = 3
#spark.executor.memory = 1g
#spark.sql.shuffle.partitions = 3000
#spark.executor.instances = 4
#spark.eventLog.enabled=true
#spark.eventLog.compress=true
#spark.eventLog.dir=file:///tmp/spark-events
#spark.history.fs.logDirectory=file:///tmp/spark-events
#spark.yarn.historyServer.address=10.0.30.101:18080
#spark.yarn.queue = scheduler
#/opt/apps/spark/bin/spark-submit --class cn.ac.iie.Main.dns.DnsOffline --master yarn --deploy-mode cluster --driver-memory 1g --executor-memory 2g --executor-cores 3 --num-executors 4 --queue scheduler  ~/Hours-0.1a.jar